# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-3.5-turbo

# Ollama Configuration (for local models)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=mistral:instruct

# LM Studio Configuration (for local models)
LMSTUDIO_HOST=http://localhost:1234

# API Configuration
DEBUG=false
OUTPUT_DIR=./outputs
MAX_FILE_SIZE=10485760

# CORS Settings
CORS_ORIGINS=["http://localhost:5173","http://localhost:3000"]
